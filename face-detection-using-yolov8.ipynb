{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5377440,"sourceType":"datasetVersion","datasetId":3119215}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Let's build a human-face detector using state-of-the-art YOLOv8","metadata":{"execution":{"iopub.status.busy":"2023-07-14T06:54:05.711169Z","iopub.execute_input":"2023-07-14T06:54:05.713645Z","iopub.status.idle":"2023-07-14T06:54:05.909408Z","shell.execute_reply.started":"2023-07-14T06:54:05.713605Z","shell.execute_reply":"2023-07-14T06:54:05.908463Z"}}},{"cell_type":"code","source":"# Importing necessary libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport shutil\nimport cv2\nimport random\nimport matplotlib.pyplot as plt\nimport copy\nimport wandb","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:21:14.215685Z","iopub.execute_input":"2023-08-04T16:21:14.216255Z","iopub.status.idle":"2023-08-04T16:21:15.002785Z","shell.execute_reply.started":"2023-08-04T16:21:14.216212Z","shell.execute_reply":"2023-08-04T16:21:15.001862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You will need a unique API key to log in to Weights & Biases. \n\n1. If you don't have a Weights & Biases account, you can go to https://wandb.ai/site and create a FREE account.\n2. Access your API key: https://wandb.ai/authorize.\n\nThere are two ways you can login using a Kaggle kernel:\n\n1. Run a cell with `wandb.login()`. It will ask for the API key, which you can copy + paste in.\n2. You can also use Kaggle secrets to store your API key and use the code snippet below to login. Check out this [discussion post](https://www.kaggle.com/product-feedback/114053) to learn more about Kaggle secrets. \n\n","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb_api\")","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:21:39.835613Z","iopub.execute_input":"2023-08-04T16:21:39.83638Z","iopub.status.idle":"2023-08-04T16:21:40.089595Z","shell.execute_reply.started":"2023-08-04T16:21:39.836342Z","shell.execute_reply":"2023-08-04T16:21:40.088614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.login(key=secret_value_0)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:21:40.914626Z","iopub.execute_input":"2023-08-04T16:21:40.915601Z","iopub.status.idle":"2023-08-04T16:21:46.433973Z","shell.execute_reply.started":"2023-08-04T16:21:40.915556Z","shell.execute_reply":"2023-08-04T16:21:46.433024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Defining some variables which will be needed later","metadata":{}},{"cell_type":"code","source":"bs=' ' # blank-space\nclass_id=0 # id for face\nnewline='\\n' # new line character\nextension='.txt' # extension for text file","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:21:51.851637Z","iopub.execute_input":"2023-08-04T16:21:51.852263Z","iopub.status.idle":"2023-08-04T16:21:51.857328Z","shell.execute_reply.started":"2023-08-04T16:21:51.852226Z","shell.execute_reply":"2023-08-04T16:21:51.856212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Separating paths for training, validation and test datasets for both images and labels","metadata":{}},{"cell_type":"code","source":"# Creating paths for separate images and labels\ncurr_path=os.getcwd()\nimgtrainpath = os.path.join(curr_path,'images','train')\nimgvalpath=os.path.join(curr_path,'images','validation')\nimgtestpath=os.path.join(curr_path,'images','test')\n\nlabeltrainpath=os.path.join(curr_path,'labels','train')\nlabelvalpath=os.path.join(curr_path,'labels','validation')\nlabeltestpath=os.path.join(curr_path,'labels','test')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:21:52.638596Z","iopub.execute_input":"2023-08-04T16:21:52.638994Z","iopub.status.idle":"2023-08-04T16:21:52.64596Z","shell.execute_reply.started":"2023-08-04T16:21:52.638959Z","shell.execute_reply":"2023-08-04T16:21:52.644472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Labels path is where all labels will be stored first before dividing them in train, validation and test","metadata":{}},{"cell_type":"code","source":"# Defining data path and labels_path\ndata_path='/kaggle/input/human-faces-object-detection'\nlabels_path = os.path.join(curr_path, 'face_labels')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:21:56.254599Z","iopub.execute_input":"2023-08-04T16:21:56.255607Z","iopub.status.idle":"2023-08-04T16:21:56.260839Z","shell.execute_reply.started":"2023-08-04T16:21:56.255561Z","shell.execute_reply":"2023-08-04T16:21:56.25979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating labels path\nos.makedirs(labels_path)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:21:59.063588Z","iopub.execute_input":"2023-08-04T16:21:59.064289Z","iopub.status.idle":"2023-08-04T16:21:59.070185Z","shell.execute_reply.started":"2023-08-04T16:21:59.064254Z","shell.execute_reply":"2023-08-04T16:21:59.068882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking Input data","metadata":{}},{"cell_type":"code","source":"# Checking input data contents\nos.listdir(data_path)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:01.277545Z","iopub.execute_input":"2023-08-04T16:22:01.277911Z","iopub.status.idle":"2023-08-04T16:22:01.290555Z","shell.execute_reply.started":"2023-08-04T16:22:01.277878Z","shell.execute_reply":"2023-08-04T16:22:01.289351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining input images and raw annotations path\nimg_path=os.path.join(data_path, 'images')\nraw_annotations_path=os.path.join(data_path, 'faces.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:03.677618Z","iopub.execute_input":"2023-08-04T16:22:03.677974Z","iopub.status.idle":"2023-08-04T16:22:03.683128Z","shell.execute_reply.started":"2023-08-04T16:22:03.677942Z","shell.execute_reply":"2023-08-04T16:22:03.682052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a list of all images\nface_list=os.listdir(img_path)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:04.042628Z","iopub.execute_input":"2023-08-04T16:22:04.043326Z","iopub.status.idle":"2023-08-04T16:22:04.622091Z","shell.execute_reply.started":"2023-08-04T16:22:04.04329Z","shell.execute_reply":"2023-08-04T16:22:04.621123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"face_list[:5]","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:04.623991Z","iopub.execute_input":"2023-08-04T16:22:04.624749Z","iopub.status.idle":"2023-08-04T16:22:04.631742Z","shell.execute_reply.started":"2023-08-04T16:22:04.624702Z","shell.execute_reply":"2023-08-04T16:22:04.630499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_len=len(face_list)\ndata_len","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:04.876528Z","iopub.execute_input":"2023-08-04T16:22:04.876887Z","iopub.status.idle":"2023-08-04T16:22:04.883038Z","shell.execute_reply.started":"2023-08-04T16:22:04.876857Z","shell.execute_reply":"2023-08-04T16:22:04.882061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### So, there are total 2204 images. Let's shuffle them","metadata":{}},{"cell_type":"code","source":"random.shuffle(face_list)\n# Checking if they are shuffled\nface_list[:5]","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:05.570359Z","iopub.execute_input":"2023-08-04T16:22:05.570707Z","iopub.status.idle":"2023-08-04T16:22:05.581073Z","shell.execute_reply.started":"2023-08-04T16:22:05.570678Z","shell.execute_reply":"2023-08-04T16:22:05.579963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Defining the train, validation and test split as 80%, 10% and 10% respectively","metadata":{}},{"cell_type":"code","source":"train_split=0.8\nval_split=0.1\ntest_split=0.1","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:06.146749Z","iopub.execute_input":"2023-08-04T16:22:06.147124Z","iopub.status.idle":"2023-08-04T16:22:06.152328Z","shell.execute_reply.started":"2023-08-04T16:22:06.147091Z","shell.execute_reply":"2023-08-04T16:22:06.151164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Separating input data on train, validation and test sets","metadata":{}},{"cell_type":"code","source":"imgtrain_list=face_list[:int(data_len*train_split)]\nimgval_list=face_list[int(data_len*train_split):int(data_len*(train_split+val_split))]\nimgtest_list=face_list[int(data_len*(train_split+val_split)):]","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:08.323602Z","iopub.execute_input":"2023-08-04T16:22:08.324328Z","iopub.status.idle":"2023-08-04T16:22:08.330312Z","shell.execute_reply.started":"2023-08-04T16:22:08.324285Z","shell.execute_reply":"2023-08-04T16:22:08.329146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgtest_list[:5] # first five images in test set","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:08.574341Z","iopub.execute_input":"2023-08-04T16:22:08.574696Z","iopub.status.idle":"2023-08-04T16:22:08.581981Z","shell.execute_reply.started":"2023-08-04T16:22:08.574664Z","shell.execute_reply":"2023-08-04T16:22:08.580715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the size of train, validation and test dataset\nlen(imgtrain_list), len(imgval_list), len(imgtest_list)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:10.856551Z","iopub.execute_input":"2023-08-04T16:22:10.857499Z","iopub.status.idle":"2023-08-04T16:22:10.86455Z","shell.execute_reply.started":"2023-08-04T16:22:10.857453Z","shell.execute_reply":"2023-08-04T16:22:10.86355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### YOLOv8 requires text file for every image. The text file should have the same name as the image file, only the image extension should be replaced by text extension. This text file contains the bounding box information of the objects in the corresponding image","metadata":{}},{"cell_type":"code","source":"# function to extract basename from a file and add a different extension to it. \ndef change_extension(file):\n    basename=os.path.splitext(file)[0]\n    filename=basename+extension\n    return filename","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:13.979008Z","iopub.execute_input":"2023-08-04T16:22:13.979671Z","iopub.status.idle":"2023-08-04T16:22:13.984643Z","shell.execute_reply.started":"2023-08-04T16:22:13.979638Z","shell.execute_reply":"2023-08-04T16:22:13.983429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Creating the lists of text files corresponding to the images in each of the sets","metadata":{}},{"cell_type":"code","source":"labeltrain_list = list(map(change_extension, imgtrain_list)) \nlabelval_list = list(map(change_extension, imgval_list)) \nlabeltest_list = list(map(change_extension, imgtest_list)) ","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:17.273654Z","iopub.execute_input":"2023-08-04T16:22:17.274626Z","iopub.status.idle":"2023-08-04T16:22:17.285823Z","shell.execute_reply.started":"2023-08-04T16:22:17.274588Z","shell.execute_reply":"2023-08-04T16:22:17.284743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking if the list of text files are created correctly \nlen(labeltrain_list), len(labelval_list), len(labeltest_list)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:17.583411Z","iopub.execute_input":"2023-08-04T16:22:17.583762Z","iopub.status.idle":"2023-08-04T16:22:17.590009Z","shell.execute_reply.started":"2023-08-04T16:22:17.583725Z","shell.execute_reply":"2023-08-04T16:22:17.588964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlabeltest_list[:5] # matches with the first five images of test set","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:19.423652Z","iopub.execute_input":"2023-08-04T16:22:19.424803Z","iopub.status.idle":"2023-08-04T16:22:19.431771Z","shell.execute_reply.started":"2023-08-04T16:22:19.424761Z","shell.execute_reply":"2023-08-04T16:22:19.430544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Reading the annotations file","metadata":{}},{"cell_type":"code","source":"raw_annotations=pd.read_csv(raw_annotations_path)\nraw_annotations","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:23.993588Z","iopub.execute_input":"2023-08-04T16:22:23.993946Z","iopub.status.idle":"2023-08-04T16:22:24.031333Z","shell.execute_reply.started":"2023-08-04T16:22:23.993914Z","shell.execute_reply":"2023-08-04T16:22:24.030188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The raw annotations contain the diagonal points of the bounding box. YOLOv8 expects the bounding box information in the form of centre coordinates, width and height of the bounding box. So let's transform the information in the required format.","metadata":{}},{"cell_type":"code","source":"raw_annotations['x_centre']=0.5*(raw_annotations['x0']+raw_annotations['x1'])\nraw_annotations['y_centre']=0.5*(raw_annotations['y0']+raw_annotations['y1'])\nraw_annotations['bb_width']=raw_annotations['x1']-raw_annotations['x0']\nraw_annotations['bb_height']=raw_annotations['y1']-raw_annotations['y0']\nraw_annotations","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:27.525546Z","iopub.execute_input":"2023-08-04T16:22:27.52627Z","iopub.status.idle":"2023-08-04T16:22:27.554495Z","shell.execute_reply.started":"2023-08-04T16:22:27.526234Z","shell.execute_reply":"2023-08-04T16:22:27.553206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Also the dimensions of bounding box are to be normalised with respect to image width and height","metadata":{}},{"cell_type":"code","source":"raw_annotations['xcentre_scaled']=raw_annotations['x_centre']/raw_annotations['width']\nraw_annotations['ycentre_scaled']=raw_annotations['y_centre']/raw_annotations['height']\nraw_annotations['width_scaled']=raw_annotations['bb_width']/raw_annotations['width']\nraw_annotations['height_scaled']=raw_annotations['bb_height']/raw_annotations['height']\nraw_annotations","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:31.375841Z","iopub.execute_input":"2023-08-04T16:22:31.376228Z","iopub.status.idle":"2023-08-04T16:22:31.407074Z","shell.execute_reply.started":"2023-08-04T16:22:31.376194Z","shell.execute_reply":"2023-08-04T16:22:31.406175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(raw_annotations['image_name'].unique())","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:34.297655Z","iopub.execute_input":"2023-08-04T16:22:34.298086Z","iopub.status.idle":"2023-08-04T16:22:34.309199Z","shell.execute_reply.started":"2023-08-04T16:22:34.298049Z","shell.execute_reply":"2023-08-04T16:22:34.308066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### So we have 2204 unique labels. The dataset is consistent.","metadata":{}},{"cell_type":"markdown","source":"# Label files creation","metadata":{}},{"cell_type":"markdown","source":"##### Creating a text file for every image with the bounding box information in correct format. The correct format for each bounding box is as follows:\n##### class_id &nbsp; x_centre &nbsp; y_centre &nbsp; width &nbsp; height\n##### This is for every single bounding box. So, if there are multiple objects to detect in one image, there will be as many lines ","metadata":{}},{"cell_type":"code","source":"# Getting all unique images\nimgs=raw_annotations.groupby('image_name') ","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:38.493551Z","iopub.execute_input":"2023-08-04T16:22:38.49392Z","iopub.status.idle":"2023-08-04T16:22:38.499061Z","shell.execute_reply.started":"2023-08-04T16:22:38.493888Z","shell.execute_reply":"2023-08-04T16:22:38.497996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image in imgs:\n    img_df=imgs.get_group(image[0])\n    basename=os.path.splitext(image[0])[0]\n    txt_file=basename+extension\n    filepath=os.path.join(labels_path, txt_file)\n    lines=[]\n    i=1\n    for index,row in img_df.iterrows():\n        if i!=len(img_df):\n            line=str(class_id)+bs+str(row['xcentre_scaled'])+bs+str(row['ycentre_scaled'])+bs+str(row['width_scaled'])+bs+str(row['height_scaled'])+newline\n            lines.append(line)\n        else:\n            line=str(class_id)+bs+str(row['xcentre_scaled'])+bs+str(row['ycentre_scaled'])+bs+str(row['width_scaled'])+bs+ str(row['height_scaled'])\n            lines.append(line)\n        i=i+1\n    with open(filepath, 'w') as file:\n        file.writelines(lines)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:41.368864Z","iopub.execute_input":"2023-08-04T16:22:41.369258Z","iopub.status.idle":"2023-08-04T16:22:42.657181Z","shell.execute_reply.started":"2023-08-04T16:22:41.369224Z","shell.execute_reply":"2023-08-04T16:22:42.656158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the labels directory\nos.listdir(labels_path)[:5]","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:45.047429Z","iopub.execute_input":"2023-08-04T16:22:45.047788Z","iopub.status.idle":"2023-08-04T16:22:45.058181Z","shell.execute_reply.started":"2023-08-04T16:22:45.047758Z","shell.execute_reply":"2023-08-04T16:22:45.057113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Let's check what are the contents of any random label file created","metadata":{}},{"cell_type":"code","source":"random_file=os.path.join(labels_path, os.listdir(labels_path)[4])\nwith open (random_file, 'r') as f:\n    content=f.read()\ncontent","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:45.83141Z","iopub.execute_input":"2023-08-04T16:22:45.831782Z","iopub.status.idle":"2023-08-04T16:22:45.841408Z","shell.execute_reply.started":"2023-08-04T16:22:45.831752Z","shell.execute_reply":"2023-08-04T16:22:45.840307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### This shows the bounding box data for this image and the order is same as mentioned earlier for every single object present","metadata":{}},{"cell_type":"code","source":"def_size=640 # Image size for YOLOv8","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:50.52858Z","iopub.execute_input":"2023-08-04T16:22:50.52894Z","iopub.status.idle":"2023-08-04T16:22:50.533713Z","shell.execute_reply.started":"2023-08-04T16:22:50.52891Z","shell.execute_reply":"2023-08-04T16:22:50.532435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(os.listdir(labels_path)) # Verifying all labels are created","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:53.23926Z","iopub.execute_input":"2023-08-04T16:22:53.240068Z","iopub.status.idle":"2023-08-04T16:22:53.249397Z","shell.execute_reply.started":"2023-08-04T16:22:53.240031Z","shell.execute_reply":"2023-08-04T16:22:53.248374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Writing functions to move label files and copy images from their source to train, validation and test directories","metadata":{}},{"cell_type":"code","source":"# function to move files from source to detination\ndef move_files(data_list, source_path, destination_path):\n    i=0\n    for file in data_list:\n        filepath=os.path.join(source_path, file)\n        dest_path=os.path.join(data_path, destination_path)\n        if not os.path.isdir(dest_path):\n            os.makedirs(dest_path)\n        shutil.move(filepath, dest_path)\n        i=i+1\n    print(\"Number of files transferred:\", i)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:53.953527Z","iopub.execute_input":"2023-08-04T16:22:53.953901Z","iopub.status.idle":"2023-08-04T16:22:53.960296Z","shell.execute_reply.started":"2023-08-04T16:22:53.953869Z","shell.execute_reply":"2023-08-04T16:22:53.959252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to resize the images and copy the resized image to destination\ndef move_images(data_list, source_path, destination_path):\n    i=0\n    for file in data_list:\n        filepath=os.path.join(source_path, file)\n        dest_path=os.path.join(data_path, destination_path)\n        \n        if not os.path.isdir(dest_path):\n            os.makedirs(dest_path)\n        finalimage_path=os.path.join(dest_path, file)\n        img_resized=cv2.resize(cv2.imread(filepath), (def_size, def_size))\n        cv2.imwrite(finalimage_path, img_resized)\n        i=i+1\n    print(\"Number of files transferred:\", i)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:22:56.976829Z","iopub.execute_input":"2023-08-04T16:22:56.977385Z","iopub.status.idle":"2023-08-04T16:22:56.984123Z","shell.execute_reply.started":"2023-08-04T16:22:56.97735Z","shell.execute_reply":"2023-08-04T16:22:56.983216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Moving images from source to train, validation and test directories","metadata":{}},{"cell_type":"code","source":"move_images(imgtrain_list, img_path, imgtrainpath)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:23:06.082248Z","iopub.execute_input":"2023-08-04T16:23:06.082603Z","iopub.status.idle":"2023-08-04T16:24:08.248806Z","shell.execute_reply.started":"2023-08-04T16:23:06.082573Z","shell.execute_reply":"2023-08-04T16:24:08.247836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"move_images(imgval_list, img_path, imgvalpath)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:26:13.129819Z","iopub.execute_input":"2023-08-04T16:26:13.130367Z","iopub.status.idle":"2023-08-04T16:26:20.244418Z","shell.execute_reply.started":"2023-08-04T16:26:13.130327Z","shell.execute_reply":"2023-08-04T16:26:20.243427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"move_images(imgtest_list, img_path, imgtestpath)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:26:25.339726Z","iopub.execute_input":"2023-08-04T16:26:25.340094Z","iopub.status.idle":"2023-08-04T16:26:32.820035Z","shell.execute_reply.started":"2023-08-04T16:26:25.340063Z","shell.execute_reply":"2023-08-04T16:26:32.819008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Moving labels from source to train, validation and test directories","metadata":{}},{"cell_type":"code","source":"move_files(labeltrain_list, labels_path, labeltrainpath)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:26:36.911993Z","iopub.execute_input":"2023-08-04T16:26:36.912686Z","iopub.status.idle":"2023-08-04T16:26:37.030937Z","shell.execute_reply.started":"2023-08-04T16:26:36.912649Z","shell.execute_reply":"2023-08-04T16:26:37.029989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"move_files(labelval_list, labels_path, labelvalpath)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:26:38.461259Z","iopub.execute_input":"2023-08-04T16:26:38.461622Z","iopub.status.idle":"2023-08-04T16:26:38.480905Z","shell.execute_reply.started":"2023-08-04T16:26:38.461592Z","shell.execute_reply":"2023-08-04T16:26:38.47988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"move_files(labeltest_list, labels_path, labeltestpath)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:26:38.951581Z","iopub.execute_input":"2023-08-04T16:26:38.951972Z","iopub.status.idle":"2023-08-04T16:26:38.97152Z","shell.execute_reply.started":"2023-08-04T16:26:38.951941Z","shell.execute_reply":"2023-08-04T16:26:38.970294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Checking if all the label files are moved","metadata":{}},{"cell_type":"code","source":"len(os.listdir(labels_path)) ","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:26:42.879669Z","iopub.execute_input":"2023-08-04T16:26:42.880544Z","iopub.status.idle":"2023-08-04T16:26:42.889821Z","shell.execute_reply.started":"2023-08-04T16:26:42.880497Z","shell.execute_reply":"2023-08-04T16:26:42.888861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.rmtree(labels_path) # removing labels path as it is empty","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:26:43.163494Z","iopub.execute_input":"2023-08-04T16:26:43.164128Z","iopub.status.idle":"2023-08-04T16:26:43.169942Z","shell.execute_reply.started":"2023-08-04T16:26:43.164096Z","shell.execute_reply":"2023-08-04T16:26:43.169001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating config file","metadata":{}},{"cell_type":"markdown","source":"#### Below is the format of config file for YOLOv8","metadata":{}},{"cell_type":"markdown","source":"train: images/train  # train images <br>\nval: images/val  # val images <br>\ntest:  # test images (optional) <br>\n<br>\nnames: <br>\n  0: person <br>\n  1: bicycle <br>\n  2: car <br>\n  ... <br>\n  77: teddy bear <br>\n  78: hair drier <br>\n  79: toothbrush\n","metadata":{}},{"cell_type":"markdown","source":"##### Creating and writing the config file in the above format","metadata":{}},{"cell_type":"code","source":"ln_1='# Train/val/test sets'+newline\nln_2='train: ' +\"'\"+imgtrainpath+\"'\"+newline\nln_3='val: ' +\"'\" + imgvalpath+\"'\"+newline\nln_4='test: ' +\"'\" + imgtestpath+\"'\"+newline\nln_5=newline\nln_6='# Classes'+newline\nln_7='names:'+newline\nln_8='  0: face'\nconfig_lines=[ln_1, ln_2, ln_3, ln_4, ln_5, ln_6, ln_7, ln_8]","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:26:46.968574Z","iopub.execute_input":"2023-08-04T16:26:46.969288Z","iopub.status.idle":"2023-08-04T16:26:46.975298Z","shell.execute_reply.started":"2023-08-04T16:26:46.969255Z","shell.execute_reply":"2023-08-04T16:26:46.974283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating path for config file\nconfig_path=os.path.join(curr_path, 'config.yaml')\nconfig_path","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:26:47.411787Z","iopub.execute_input":"2023-08-04T16:26:47.412466Z","iopub.status.idle":"2023-08-04T16:26:47.418607Z","shell.execute_reply.started":"2023-08-04T16:26:47.412432Z","shell.execute_reply":"2023-08-04T16:26:47.417539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Writing config file\nwith open(config_path, 'w') as f:\n    f.writelines(config_lines)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:26:51.382866Z","iopub.execute_input":"2023-08-04T16:26:51.383262Z","iopub.status.idle":"2023-08-04T16:26:51.38886Z","shell.execute_reply.started":"2023-08-04T16:26:51.383227Z","shell.execute_reply":"2023-08-04T16:26:51.387847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Visualisation","metadata":{}},{"cell_type":"markdown","source":"#### Let's write a function to obtain bounding box coordinates from text label files.","metadata":{}},{"cell_type":"code","source":"# function to obtain bounding box  coordinates from text label files\ndef get_bbox_from_label(text_file_path):\n    bbox_list=[]\n    with open(text_file_path, \"r\") as file:\n        for line in file:\n            _,x_centre,y_centre,width,height=line.strip().split(\" \")\n            x1=(float(x_centre)+(float(width)/2))*def_size\n            x0=(float(x_centre)-(float(width)/2))*def_size\n            y1=(float(y_centre)+(float(height)/2))*def_size\n            y0=(float(y_centre)-(float(height)/2))*def_size\n            \n            vertices=np.array([[int(x0), int(y0)], [int(x1), int(y0)], \n                               [int(x1),int(y1)], [int(x0),int(y1)]])\n#             vertices=vertices.reshape((-1,1,2))\n            bbox_list.append(vertices)      \n            \n    return tuple(bbox_list)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:26:54.507816Z","iopub.execute_input":"2023-08-04T16:26:54.508534Z","iopub.status.idle":"2023-08-04T16:26:54.516235Z","shell.execute_reply.started":"2023-08-04T16:26:54.508497Z","shell.execute_reply":"2023-08-04T16:26:54.515206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Drawing bouding box around faces in some randomly selected images in training dataset using training labels ","metadata":{}},{"cell_type":"code","source":"# defining red color in RGB to draw bounding box\nred=(255,0,0) ","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:26:57.783583Z","iopub.execute_input":"2023-08-04T16:26:57.784289Z","iopub.status.idle":"2023-08-04T16:26:57.789155Z","shell.execute_reply.started":"2023-08-04T16:26:57.784255Z","shell.execute_reply":"2023-08-04T16:26:57.788224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\nfor i in range(1,8,2):\n    k=random.randint(0, len(imgtrain_list)-1)\n    img_path=os.path.join(imgtrainpath, imgtrain_list[k])\n    label_path=os.path.join(labeltrainpath, labeltrain_list[k])\n    bbox=get_bbox_from_label(label_path)\n    image=cv2.imread(img_path)\n    image_copy=copy.deepcopy(image)\n    ax=plt.subplot(4, 2, i)\n    plt.imshow(image) # displaying image\n    plt.xticks([])\n    plt.yticks([])\n    cv2.drawContours(image_copy, bbox, -1, red, 2) # drawing bounding box on copy of image\n    ax=plt.subplot(4, 2, i+1)\n    plt.imshow(image_copy) # displaying image with bounding box\n    plt.xticks([])\n    plt.yticks([])","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:26:58.157597Z","iopub.execute_input":"2023-08-04T16:26:58.158265Z","iopub.status.idle":"2023-08-04T16:27:00.087562Z","shell.execute_reply.started":"2023-08-04T16:26:58.158229Z","shell.execute_reply":"2023-08-04T16:27:00.086314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### These images validate the created text file labels and show that we are good to go for training","metadata":{}},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"#### Let's install ultralytics and use YOLOv8 to detect faces","metadata":{}},{"cell_type":"code","source":"# Installing ultralytics\n!pip install ultralytics","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:27:09.94123Z","iopub.execute_input":"2023-08-04T16:27:09.941588Z","iopub.status.idle":"2023-08-04T16:27:23.231459Z","shell.execute_reply.started":"2023-08-04T16:27:09.941557Z","shell.execute_reply":"2023-08-04T16:27:23.230272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLO","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:27:27.461467Z","iopub.execute_input":"2023-08-04T16:27:27.461842Z","iopub.status.idle":"2023-08-04T16:27:32.236624Z","shell.execute_reply.started":"2023-08-04T16:27:27.461804Z","shell.execute_reply":"2023-08-04T16:27:32.235646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using YOLO's ptetrained model architecture and weights for training\nmodel=YOLO('yolov8n.yaml').load('yolov8n.pt')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:27:38.626081Z","iopub.execute_input":"2023-08-04T16:27:38.626827Z","iopub.status.idle":"2023-08-04T16:27:39.920462Z","shell.execute_reply.started":"2023-08-04T16:27:38.626792Z","shell.execute_reply":"2023-08-04T16:27:39.919511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model\nresults=model.train(data=config_path, epochs=100, resume=True, iou=0.5, conf=0.001)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T16:27:53.390074Z","iopub.execute_input":"2023-08-04T16:27:53.390895Z","iopub.status.idle":"2023-08-04T16:35:47.97302Z","shell.execute_reply.started":"2023-08-04T16:27:53.39086Z","shell.execute_reply":"2023-08-04T16:35:47.971619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Results can be converted to a zip file using the following command which is commented right now. This zip file can be downloaded later if results are to be analysed locally","metadata":{}},{"cell_type":"code","source":"# !zip -r results.zip /kaggle/working/runs/detect/train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### mAP50 is the average precision value obtained by model at 50% IoU. This is the default metric used by YOLOv8 for object detection tasks.","metadata":{}},{"cell_type":"markdown","source":"#### Let's see how the training progressed with epochs by visualizing the plots","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\ntrainingresult_path=os.path.join(curr_path, 'runs', 'detect', 'train')\nresults_png=cv2.imread(os.path.join(trainingresult_path,'results.png'))\nplt.imshow(results_png)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:53:30.946044Z","iopub.execute_input":"2023-08-02T16:53:30.947258Z","iopub.status.idle":"2023-08-02T16:53:32.460919Z","shell.execute_reply.started":"2023-08-02T16:53:30.947217Z","shell.execute_reply":"2023-08-02T16:53:32.459844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### All losses- Box loss, class loss, dfl loss are decreasing with epochs.\n#### All metrics- Precision, Recall, mAP50 and mAP50-95 are increasing with epochs","metadata":{}},{"cell_type":"markdown","source":"#### Let's check the model performance on training, validation and test datasets","metadata":{}},{"cell_type":"markdown","source":"# Model Performance ","metadata":{}},{"cell_type":"markdown","source":"##### Let's write functions for evaluating model metrics and displaying plots","metadata":{}},{"cell_type":"code","source":"# function for evaluating model metrics map50\ndef evaluate_map50(trainedmodel, data_path, dataset='val'):\n    metrics=trainedmodel.val(data=data_path, split=dataset)\n    map50=round(metrics.box.map50, 3)\n    print(\"The mAP of model on {0} dataset is {1}\".format(dataset,map50))\n    return metrics, map50","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:16:09.179553Z","iopub.execute_input":"2023-08-02T11:16:09.179922Z","iopub.status.idle":"2023-08-02T11:16:09.192591Z","shell.execute_reply.started":"2023-08-02T11:16:09.17989Z","shell.execute_reply":"2023-08-02T11:16:09.19149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function for displaying plots created by YOLO\ndef display_curves(root_path):\n    plt.figure(figsize=(50,50))\n    \n    #displaying p curve\n    p_curve=cv2.imread(os.path.join(root_path,'P_curve.png'))\n    ax=plt.subplot(5,1,1)\n    plt.imshow(p_curve)\n    \n    #displaying r curve\n    r_curve=cv2.imread(os.path.join(root_path,'R_curve.png'))\n    ax=plt.subplot(5,1,2)\n    plt.imshow(r_curve)\n    \n    #displaying pr curve\n    pr_curve=cv2.imread(os.path.join(root_path,'PR_curve.png'))\n    ax=plt.subplot(5,1,3)\n    plt.imshow(pr_curve)\n    \n    #displaying f1 curve\n    f1_curve=cv2.imread(os.path.join(root_path,'F1_curve.png'))\n    ax=plt.subplot(5,1,4)\n    plt.imshow(f1_curve)\n    \n    #displaying confusion matrix\n    confusion_matrix=cv2.imread(os.path.join(root_path,'confusion_matrix.png'))\n    ax=plt.subplot(5,1,5)\n    plt.imshow(confusion_matrix)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:23:03.69092Z","iopub.execute_input":"2023-08-02T11:23:03.691296Z","iopub.status.idle":"2023-08-02T11:23:03.703196Z","shell.execute_reply.started":"2023-08-02T11:23:03.691265Z","shell.execute_reply":"2023-08-02T11:23:03.701024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating train metrics\ntrain_metrics, train_map50=evaluate_map50(model, config_path, dataset='train')","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:18:17.639543Z","iopub.execute_input":"2023-08-02T11:18:17.640734Z","iopub.status.idle":"2023-08-02T11:18:44.3556Z","shell.execute_reply.started":"2023-08-02T11:18:17.640678Z","shell.execute_reply":"2023-08-02T11:18:44.354552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Path storing model's performance on training dataset","metadata":{}},{"cell_type":"code","source":"train_path=os.path.join(curr_path, 'runs', 'detect', 'val') #val is a misnomer, it is actually measuring validation on training dataset","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:19:27.009682Z","iopub.execute_input":"2023-08-02T11:19:27.01008Z","iopub.status.idle":"2023-08-02T11:19:27.020373Z","shell.execute_reply.started":"2023-08-02T11:19:27.010045Z","shell.execute_reply":"2023-08-02T11:19:27.018363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display plots on training data\ndisplay_curves(train_path)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:23:38.056244Z","iopub.execute_input":"2023-08-02T11:23:38.056642Z","iopub.status.idle":"2023-08-02T11:23:43.873551Z","shell.execute_reply.started":"2023-08-02T11:23:38.056609Z","shell.execute_reply":"2023-08-02T11:23:43.872666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating val metrics\nval_metrics, val_map50=evaluate_map50(model, config_path, dataset='val')","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:26:53.74643Z","iopub.execute_input":"2023-08-02T11:26:53.746792Z","iopub.status.idle":"2023-08-02T11:27:02.006193Z","shell.execute_reply.started":"2023-08-02T11:26:53.746763Z","shell.execute_reply":"2023-08-02T11:27:02.004947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Path storing model's performance on validation dataset","metadata":{}},{"cell_type":"code","source":"val_path=os.path.join(curr_path, 'runs', 'detect', 'val2') ","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:28:28.577099Z","iopub.execute_input":"2023-08-02T11:28:28.577546Z","iopub.status.idle":"2023-08-02T11:28:28.589823Z","shell.execute_reply.started":"2023-08-02T11:28:28.577495Z","shell.execute_reply":"2023-08-02T11:28:28.58826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display plots on validation data\ndisplay_curves(val_path)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:28:31.232394Z","iopub.execute_input":"2023-08-02T11:28:31.232822Z","iopub.status.idle":"2023-08-02T11:28:36.656598Z","shell.execute_reply.started":"2023-08-02T11:28:31.232789Z","shell.execute_reply":"2023-08-02T11:28:36.655383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating test metrics\ntest_metrics, test_map50=evaluate_map50(model, config_path, dataset='test')","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:35:46.482203Z","iopub.execute_input":"2023-08-02T11:35:46.482608Z","iopub.status.idle":"2023-08-02T11:35:55.22629Z","shell.execute_reply.started":"2023-08-02T11:35:46.482572Z","shell.execute_reply":"2023-08-02T11:35:55.225061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Path storing model's performance on test dataset","metadata":{}},{"cell_type":"code","source":"test_path=os.path.join(curr_path, 'runs', 'detect', 'val3') #val3 is a misnomer, it is actually measuring validation on test dataset","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:36:03.58623Z","iopub.execute_input":"2023-08-02T11:36:03.58664Z","iopub.status.idle":"2023-08-02T11:36:03.594954Z","shell.execute_reply.started":"2023-08-02T11:36:03.586601Z","shell.execute_reply":"2023-08-02T11:36:03.593633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display plots on test data\ndisplay_curves(test_path) ","metadata":{"execution":{"iopub.status.busy":"2023-08-02T11:36:40.490902Z","iopub.execute_input":"2023-08-02T11:36:40.492079Z","iopub.status.idle":"2023-08-02T11:36:46.641578Z","shell.execute_reply.started":"2023-08-02T11:36:40.49204Z","shell.execute_reply":"2023-08-02T11:36:46.64019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing model's performance on random test images","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(60,60))\nm=random.randint(0, 150) # Selecting random image number\nfor i in range(1,8,2):\n    test_image=os.path.join(imgtestpath, os.listdir(imgtestpath)[m])\n    ax=plt.subplot(4,2,i)\n    \n    # Display actual image\n    plt.imshow(cv2.imread(test_image)) \n    plt.xticks([])\n    plt.yticks([])\n    plt.title(\"Actual image\", fontsize = 40)\n    \n    # Predict \n    res = model(test_image)\n    res_plotted = res[0].plot()\n    ax=plt.subplot(4,2,i+1)\n    \n    # Display image with predictions\n    plt.imshow(res_plotted)\n    plt.title(\"Image with predictions\", fontsize = 40)\n    plt.xticks([])\n    plt.yticks([])\n    m=m+1","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:34:39.938264Z","iopub.execute_input":"2023-08-02T13:34:39.938995Z","iopub.status.idle":"2023-08-02T13:34:52.675546Z","shell.execute_reply.started":"2023-08-02T13:34:39.938957Z","shell.execute_reply":"2023-08-02T13:34:52.674276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### So,we see that model detects faces quite nicely. With more data and more training, it can do better","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:24:31.109099Z","iopub.execute_input":"2023-08-02T13:24:31.109508Z","iopub.status.idle":"2023-08-02T13:24:31.118845Z","shell.execute_reply.started":"2023-08-02T13:24:31.109471Z","shell.execute_reply":"2023-08-02T13:24:31.117577Z"}}}]}