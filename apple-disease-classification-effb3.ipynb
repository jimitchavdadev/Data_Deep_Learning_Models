{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3433042,"sourceType":"datasetVersion","datasetId":2068739}],"dockerImageVersionId":30177,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-09T16:19:31.05797Z","iopub.execute_input":"2022-04-09T16:19:31.058214Z","iopub.status.idle":"2022-04-09T16:19:31.061825Z","shell.execute_reply.started":"2022-04-09T16:19:31.05818Z","shell.execute_reply":"2022-04-09T16:19:31.061256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\nimport os\nimport matplotlib.pyplot as plt\n\nbase_dir = '/kaggle/input/apple-disease-dataset/datasets'\n\ntrain_dir = os.path.join(base_dir, 'train')\ntest_dir = os.path.join(base_dir, 'test')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image_size = (224, 224) # efficienetB0, ResNet50V2, DenseNet121, MobileNetV2\n# image_size = (240, 240) # efficienetB1\n# image_size = (260, 260) # efficienetB2\nimage_size = (300, 300) # efficienetB3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input_shapes = (224, 224, 3) # efficienetB0, ResNet50V2, DenseNet121, MobileNetV2\n# input_shapes = (240, 240, 3) # efficienetB1\n# input_shapes = (260, 260, 3) # efficienetB2\ninput_shapes = (300, 300, 3) # efficienetB3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nLEARNING_RATE=0.0001\nnum_classes=4","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trdata=tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=False, samplewise_center=False,\n    featurewise_std_normalization=False, samplewise_std_normalization=False,\n    rotation_range=0, width_shift_range=0.0, height_shift_range=0.0,\n    brightness_range=None, shear_range=0.0, zoom_range=0.0, channel_shift_range=0.0,\n    horizontal_flip=False, vertical_flip=False,\n    validation_split=0.2, rescale=1./255\n)\n\ntrain_ds = trdata.flow_from_directory(\n    directory=train_dir,\n    target_size=image_size,\n    class_mode=\"categorical\",\n    subset=\"training\",\n    batch_size=batch_size,\n    shuffle=True,\n)\n\nval_ds = trdata.flow_from_directory(\n    directory=train_dir,\n    target_size=image_size,\n    class_mode=\"categorical\",\n    subset=\"validation\",\n    batch_size=batch_size,\n    shuffle=True,\n)\n\ntestdata=tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=False, samplewise_center=False,\n    featurewise_std_normalization=False, samplewise_std_normalization=False,\n    rotation_range=0, width_shift_range=0.0, height_shift_range=0.0,\n    brightness_range=None, shear_range=0.0, zoom_range=0.0, channel_shift_range=0.0,\n    horizontal_flip=False, vertical_flip=False, rescale=1./255\n)\n\ntest_ds = testdata.flow_from_directory(\n    directory=test_dir,\n    target_size=image_size,\n    class_mode=\"categorical\",\n    batch_size=batch_size,\n    shuffle=False,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_batch, y_batch = next(train_ds)\n\n_, axs = plt.subplots(4, 8, figsize=(20, 10))\naxs = axs.flatten()\nfor i, ax in zip(range(0, 32), axs):\n    image = x_batch[i]\n    ax.axis(\"off\")\n    ax.imshow(image)\n\nplt.savefig(\"preprocessed.png\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U git+https://github.com/qubvel/efficientnet","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import layers\nfrom keras.layers import AveragePooling2D, BatchNormalization\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Input\nfrom keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import EfficientNetB1\nfrom tensorflow.keras.applications import EfficientNetB2\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.applications import ResNet50V2\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.applications import MobileNetV2\n\nfrom keras import optimizers\n\n# base_model = EfficientNetB0(include_top=False, input_shape=input_shapes, pooling='avg', weights=\"imagenet\",classes=num_classes)\n# base_model = EfficientNetB1(include_top=False, input_shape=input_shapes, pooling='avg', weights=\"imagenet\",classes=num_classes)\n# base_model = EfficientNetB2(include_top=False, input_shape=input_shapes, pooling='avg', weights=\"imagenet\",classes=num_classes)\nbase_model = EfficientNetB3(include_top=False, input_shape=input_shapes, pooling='avg', weights=\"imagenet\",classes=num_classes)\n# base_model = ResNet50V2(include_top=False, input_shape=input_shapes, pooling='avg', weights=\"imagenet\",classes=num_classes)\n# base_model = DenseNet121(include_top=False, input_shape=input_shapes, pooling='avg', weights=\"imagenet\",classes=num_classes)\n# base_model = MobileNetV2(include_top=False, input_shape=input_shapes, pooling='avg', weights=\"imagenet\",classes=num_classes)\n\nx = base_model.output   \n\nx = BatchNormalization()(x)\n\n# Start of Neural Network Part\nx = Dense(512,activation='sigmoid')(x)    # 128/256/512/1024\nx = BatchNormalization()(x)\n#x = Activation(swish_act)(x)\nx = Dropout(0.5)(x)  # 0.1/0.2/0.3/0.5/0.6/0.7\n\nx = Dense(128,activation='sigmoid')(x)   # 128/256/512/1024\nx = BatchNormalization()(x)\n#x = Activation(swish_act)(x)\nx = Dropout(0.7)(x)  # 0.1/0.2/0.3/0.5/0.6/0.7\n\npredictions = Dense(num_classes, activation=\"softmax\")(x)\n\nmodel= Model(inputs = base_model.input, outputs = predictions)\n\nmodel.compile(loss='categorical_crossentropy',optimizer=Adam(lr=LEARNING_RATE),metrics=['acc'])\nmodel.summary()\nmodel.save('model_base.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint,EarlyStopping\n\ncheckpoint = ModelCheckpoint('effB3.h5', monitor='val_acc',save_best_only=True,)\nearly = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\nhistory=model.fit(train_ds, epochs=epochs, callbacks=[checkpoint,early], validation_data=val_ds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport sklearn\nfrom itertools import product\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\nfrom keras.models import load_model\n\nmodel.load_weights('effB3.h5')\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes, rotation=0)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range (cm.shape[0]):\n        for j in range (cm.shape[1]):\n            plt.text(j, i, format(cm[i, j], fmt),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    plt.savefig('cnf_B3.jpg')\n\nclass_labels = test_ds.class_indices\nclass_labels = {v: k for k, v in class_labels.items()}\nclasses = list(class_labels.values())\n\n\nY_pred = model.predict_generator(test_ds)\ny_pred = np.argmax(Y_pred, axis=1)\n\ntarget_names = list(class_labels.values())\n\npredicted_classes = np.argmax(Y_pred, axis=1)\n\ncnf_matrix = confusion_matrix(test_ds.classes, y_pred)\nplt.figure(figsize=(10, 10))\nplt.rcParams.update({'font.size': 16})\n\nplot_confusion_matrix(cnf_matrix, classes=classes,\n                      title='')\nplt.show()\n\nprint(classification_report(test_ds.classes, y_pred, target_names=target_names,digits=4))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}