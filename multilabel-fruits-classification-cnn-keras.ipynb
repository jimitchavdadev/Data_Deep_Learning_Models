{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9104286,"sourceType":"datasetVersion","datasetId":5857}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Multioutput (Multilabel) Fruit Classification using CNN - Keras\n\n## Background: Fruit Classification Use Cases\nBeyond its educational aspects, fruit classification can have a significant practical value. With deep learning, we can create and explore multiple compelling use cases for this technology.\n\n**Use Case 1: Sorting Ripe Fruits**\n\nOne practical application is sorting ripe fruits from unripe ones. For instance, an automated fruit sorting system powered by Deep Learning can efficiently categorize ripe bananas from green ones, streamlining the packaging process.\n\n**Use Case 2: Detecting Spoiled Fruits**\n\nDeep Learning can aid in identifying spoiled fruits, such as detecting fungus presence on their skin. By automating this process, we can minimize waste and enhance the quality control in fruit distribution centers.\n\n**Use Case 3: Inventory Management**\n\nFruit classification can assist in inventory management for grocery stores and warehouses. With the ability to automatically classify and count different fruits in stock, businesses can optimize their supply chain and ensure adequate stock levels.\n\n**Use Case 4: Fruit Disease Detection**\n\nBy analyzing fruit images, Deep Learning models can spot signs of diseases or pests affecting the fruit's health. Early detection enables timely intervention, preventing the spread of diseases and safeguarding crop yields.\n\nWith Deep Learning's capabilities, fruit classification can be well implemented as a replacement of traditional manual methods in the agricultural, horticultural and botany domains. By utilizing these models,we can introduce efficiency and accuracy into various fruit-related processes. \n\nNow we are familiar with some great ways to use fruit classification with Deep Learning, let's begin the fruit classification model! ðŸ˜Š","metadata":{}},{"cell_type":"markdown","source":"# 1. Introduction\n\nFruits are an essential part of our daily diets. In various production processes using fruits, sorting plays a crucial role, and implementation of AI systems is revolutionizing this task with highly accurate deep learning models. \n\n### Challenge: \nIdentifying and grading fruits is a tough task due to their varying shapes, colors, and textures. The main challenges involve differentiating between different types of fruits and distinguishing among various varieties of the same fruit. Accurate fruit classification is vital for determining their prices in supermarkets.\n\n### About this notebook\nIn this Kaggle notebook, we'll build a fruit classification model using the Fruits 360 dataset. The deep learning model will be Keras-based that aims to proficiently classify ten different types of fruit.\n\nYou'll find step-by-step instructions with clear and concise code to create this powerful deep learning model.\n\nApart from the model code, we'll also perform an comprehensive EDA to explore the dataset, discuss the approach to set up the deep learning and ConvNet-based classification model and also understand how we can use the same approach for a similar product/item classification.","metadata":{}},{"cell_type":"markdown","source":"# 1.1 Importing Required Libraries and Packages","metadata":{}},{"cell_type":"code","source":"# Libraries for file and directory operations\nimport os\nimport shutil\nimport glob\nimport random\n\n# avoid warnings\nimport warnings \nwarnings. filterwarnings('ignore')\n\n# Library for data processing\nimport numpy as np\nimport math\nimport pandas as pd\n\n# Libraries for data visualization\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nfrom PIL import Image\n\n# Libraries for deep learning model\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop,Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom keras.layers.normalization.batch_normalization import BatchNormalization\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting to know the dataset: Fruits 360\n\nThe Kaggle dataset used in this notebook is the [Fruits 360 dataset](https://www.kaggle.com/datasets/moltean/fruits) (Version: 2020.05.18.0) which contains images of different fruits and vegetables.\n\n**Dataset License**: CC-BY-SA 4.0 license.","metadata":{}},{"cell_type":"markdown","source":"# 1.2 Importing & Loading the Fruits360 Dataset","metadata":{}},{"cell_type":"code","source":"# dataset path\ndataset_path = '/kaggle/input/fruits/fruits-360_dataset/fruits-360'\n\n# Define training and test folders\ntraining_folder_path = \"/kaggle/input/fruits/fruits-360_dataset/fruits-360/Training\"\ntest_folder_path = \"/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Counting total labels\ndef count_labels(folder_path):\n    label_count = 0\n    for _, dirs, _ in os.walk(folder_path):\n        label_count += len(dirs)\n        break  # Only count the top-level directories and exit the loop\n    return label_count\n\nnum_labels = count_labels(training_folder_path)\nprint(f\"Number of labels (folders) in the training dataset: {num_labels}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This means that there are 131 classes of fruits and vegetable within the dataset (including variants).","metadata":{}},{"cell_type":"markdown","source":"### Exploring labels within training folder","metadata":{}},{"cell_type":"code","source":"# Get a list of all labels (subfolder names) within the training folder\nlabels = [label for label in os.listdir(training_folder_path) if os.path.isdir(os.path.join(training_folder_path, label))]\n\n# Sort the labels alphabetically\nsorted_labels = sorted(labels)\n\n# Print the list of labels\nprint(\"Sorted Labels:\")\nfor label in sorted_labels:\n    print(label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above printed labels, we can see that a few fruits are available in more than one variety and have been separately labeled as belonging to a different class.","metadata":{}},{"cell_type":"markdown","source":"# 1.3 Sorting and filtering the dataset\n\nThe dataset contains both fruits and vegetable images as seen from the class labels. Hence, it needs to be filtered for only fruits. To achieve this, relevant folders with fruit variants need to be copied to the working directory first. ","metadata":{}},{"cell_type":"code","source":"# creating a folder for filtered dataset in the working directory\n\ndef create_folders(destination_path):\n    # Create \"filtered_dataset\" folder directly\n    os.makedirs(destination_path, exist_ok=True)\n\n    # Create \"training\" and \"test\" folders within \"filtered_dataset\"\n    training_path = os.path.join(destination_path, \"training\")\n    test_path = os.path.join(destination_path, \"test\")\n    os.makedirs(training_path, exist_ok=True)\n    os.makedirs(test_path, exist_ok=True)\n\nif __name__ == \"__main__\":\n    destination_path = \"/kaggle/working/filtered_dataset\"\n    create_folders(destination_path)\n\n    print(f\"filtered_dataset folder created successfully in {destination_path}\")\n    print(f\"Training folder created successfully in {destination_path}.\")\n    print(f\"Test folder created successfully in {destination_path}.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.4 Classification model idea and requirements\n\nAlthough a generalized model would be simpler to setup and might be able to detect different fruits, but it yet won't perform well for identifying the fruit variants.\nHence, for the model to be able to distinguish between multiple varieties of the same fruit, we will require a deeper model and a more complex model.","metadata":{}},{"cell_type":"markdown","source":"### Creating a subset of the main dataset with fruit labels","metadata":{}},{"cell_type":"markdown","source":"For this model, we will copy the following 11 fruits classes with all variant folders to both training and test datasets.\n1. Apple\n2. Banana\n3. Cherry\n4. Guava\n5. Grape\n6. Lychee\n7. Pineapple\n8. Rambutan\n9. Raspberry\n10. Redcurrant\n11. Salak","metadata":{}},{"cell_type":"code","source":"def copy_selected_folders(source_path, destination_path, selected_fruits):\n    if not os.path.exists(source_path):\n        print(\"Source path does not exist.\")\n        return\n\n    source_folders = os.listdir(source_path)\n    for fruit_pattern in selected_fruits:\n        fruit_pattern = fruit_pattern.lower()  # Make sure the fruit pattern is in lowercase\n        fruit_folder_matches = [f for f in source_folders if f.lower().startswith(fruit_pattern)]\n\n        if not fruit_folder_matches:\n            print(f\"No variants found for '{fruit_pattern}'.\")\n            continue\n\n        for source_folder in fruit_folder_matches:\n            fruit_name = source_folder\n            source_folder = os.path.join(source_path, source_folder)\n            destination_folder = os.path.join(destination_path, fruit_name)\n            try:\n                shutil.copytree(source_folder, destination_folder)\n                print(f\"Fruit '{fruit_name}' copied successfully in {destination_path}.\")\n            except FileExistsError:\n                print(f\"Fruit '{fruit_name}' already exists in the destination path.\")\n                \n# copy fruit folders to training folder\nif __name__ == \"__main__\":\n    source_path = \"/kaggle/input/fruits/fruits-360_dataset/fruits-360/Training\"\n    destination_path = \"/kaggle/working/filtered_dataset/training\"\n    \n    # Selecting the fruit names to copy all variants\n    selected_fruits = [\"Apple\",\"Banana\", \"Cherry\",\"Guava\",\"Grape\",\"Lychee\",\"Pineapple\",\"Rambutan\",\"Raspberry\",\"Redcurrant\",\"Salak\"] \n  \n    copy_selected_folders(source_path, destination_path, selected_fruits)\n    \n# copy fruit folders to test folder\nif __name__ == \"__main__\":\n    source_path = \"/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test\"\n    destination_path = \"/kaggle/working/filtered_dataset/test\"\n    \n    # Selecting the fruit names to copy all variants\n    selected_fruits = [\"Apple\",\"Banana\", \"Cherry\",\"Guava\",\"Grape\",\"Lychee\",\"Pineapple\",\"Rambutan\",\"Raspberry\",\"Redcurrant\",\"Salak\"] \n  \n    copy_selected_folders(source_path, destination_path, selected_fruits)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.5 Exploring the Dataset","metadata":{}},{"cell_type":"code","source":"training_subset=\"/kaggle/working/filtered_dataset/training\"\ntest_subset=\"/kaggle/working/filtered_dataset/test\"\n\n# function to count images in each folder\ndef count_images_per_label(folder_path):\n    label_counts = {\n        label: len(os.listdir(os.path.join(folder_path, label)))\n        for label in os.listdir(folder_path)\n        if os.path.isdir(os.path.join(folder_path, label))\n    }\n\n    return label_counts\n\nif __name__ == \"__main__\":\n    # Count images in training folders\n    training_label_counts = count_images_per_label(training_subset)\n    test_label_counts = count_images_per_label(test_subset)\n    sorted_training_label_counts = sorted(training_label_counts.items(), key=lambda x: x[1], reverse=True)\n    sorted_test_label_counts = sorted(test_label_counts.items(), key=lambda x: x[1], reverse=True)\nprint(\"Training Label Counts (sorted by count):\")\nfor label, count in sorted_training_label_counts:\n    print(f\"{label}: {count}\")\nprint(\"Test Label Counts (sorted by count):\")\nfor label, count in sorted_test_label_counts:\n    print(f\"{label}: {count}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#counting number of images\ndef count_total_images(folder_path):\n    total_images = 0\n    for _, _, files in os.walk(folder_path):\n        total_images += len(files)\n    return total_images\n\ntotal_images_count = count_total_images(dataset_path)\ntotal_train_images_count = count_total_images(training_subset)\ntotal_test_images_count = count_total_images(test_subset)\n\n#Display total number of images in each folder of the dataset\nprint(f\"Total number of images in the main dataset: {total_images_count}\")\nprint(f\"Total number of images in the training dataset: {total_train_images_count}\")\nprint(f\"Total number of images in the test dataset: {total_test_images_count}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine the training and test label counts into a single dictionary\ncombined_label_counts = {\n    label: training_label_counts.get(label, 0) + test_label_counts.get(label, 0)\n    for label in set(list(training_label_counts.keys()) + list(test_label_counts.keys()))\n}\n\n# Create a DataFrame to hold the combined fruit counts\ndf_fruit_counts = pd.DataFrame({\"Fruit Labels\": list(combined_label_counts.keys()), \"Count\": list(combined_label_counts.values())})\n\n# Sort the DataFrame by the counts in descending order\ndf_fruit_counts = df_fruit_counts.sort_values(by=\"Count\", ascending=False)\n\n# Select the top 15 fruit labels by count\ntop_15_fruits = df_fruit_counts.head(15)\n\n# Plot the horizontal bar chart using Seaborn\nplt.figure(figsize=(10, 8))\nsns.barplot(x=\"Count\", y=\"Fruit Labels\", data=top_15_fruits, palette=\"YlOrRd\")\nplt.xlabel(\"Count\")\nplt.ylabel(\"Fruit Labels\")\nplt.title(\"Top 15 Fruit Labels by Count\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32\nIMAGE_SIZE = 100\nCHANNELS = 3\nEPOCHS = 10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training dataset pipeline\ntrain_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    training_subset,\n    seed=42,\n    shuffle=True,\n    image_size=(IMAGE_SIZE,IMAGE_SIZE),\n    batch_size=BATCH_SIZE\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print training labels\ntr_class_names = train_dataset.class_names\ntr_class_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Exploration**","metadata":{}},{"cell_type":"code","source":"#visualizing sample images from the dataset\nplt.figure(figsize=(10, 10))\nfor image_batch, labels_batch in train_dataset.take(9):\n    for i in range(25):\n        ax = plt.subplot(5,5, i + 1)\n        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n        plt.title(tr_class_names[labels_batch[i]], fontsize=10)\n        plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.6 Preparing dataset","metadata":{}},{"cell_type":"markdown","source":"Next, let us split the data in the training folder into train and validation sets. The train set will be used to train the model, while the validation set will help evaluate the model performance and will also help to reduce overfitting, if any during training.","metadata":{}},{"cell_type":"code","source":"# define a function to split the dataset \ndef get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.2, shuffle=True, shuffle_size=10000):\n    assert (train_split + val_split) == 1\n\n    ds_size = len(ds)\n\n    if shuffle:\n        ds = ds.shuffle(shuffle_size, seed=1234)\n\n    train_size = int(train_split * ds_size)\n    val_size = int(val_split * ds_size)\n\n    train_ds = ds.take(train_size)\n    val_ds = ds.skip(train_size).take(val_size)\n\n    return train_ds, val_ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds, val_ds = get_dataset_partitions_tf(train_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print length of each set\nprint(\"Training dataset length\",len(train_ds))\nprint(\"Validation dataset length\",len(val_ds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optimization for Training and Validation Datasets by caching and shuffling\ntrain_ds = train_ds.cache().shuffle(100).prefetch(buffer_size=tf.data.AUTOTUNE)\nval_ds = val_ds.cache().shuffle(100).prefetch(buffer_size=tf.data.AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resize and rescaling images to a specified size \nresize_and_rescale = tf.keras.Sequential([\n  layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n  layers.experimental.preprocessing.Rescaling(1./255),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prefetching the training data to optimize pipeline\ntrain_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Building a multi-task or multi-output model in Keras","metadata":{}},{"cell_type":"code","source":"# Defining the shape of the input data batch for CNN\ninput_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n\n# Number of outputs\nn_classes = len(tr_class_names)\nn_classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.1 Defining the CNN","metadata":{}},{"cell_type":"markdown","source":"Let us now define our CNN model with the Sequential API in Keras using the input_shape specified in the previous step.\nThis model will consist of multiple Conv2D and MaxPooling2D layers, followed by a Flatten layer, two Dense layers with dropout regularization, and a finally a Dense layer with softmax activation for multi-class classification\nAlso, the n_classes will represent the number of output classes.","metadata":{}},{"cell_type":"code","source":"# CNN model\nmodel = Sequential([\n    resize_and_rescale,\n    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(32, kernel_size = (3,3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    \n    layers.Conv2D(64, kernel_size =(3,3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(64, kernel_size =(3,3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(128, kernel_size = (3,3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Flatten(),\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.25),\n    layers.Dense(n_classes, activation='softmax'),\n])\n\nmodel.build(input_shape=input_shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Review the model summary\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Choice of Optimizer\nTo build this fruit image classifier, we are using RMSprop instead of Adam due to its ability to handle sparse gradients. This can be an advantage as we have a multilabel task. This means we are dealing with sparse gradients due to multiple categories and sub categories.\nAlso our dataset has a varying complexities and different number of images in each class. \nThus, RMSprop can be used instead of adam to leverage its adaptive learning rate mechanism for a better fine-tuning to learning rates. This can possibly provide a better convergence and performance on our specific image classification task. ","metadata":{}},{"cell_type":"code","source":"# specifying the optimizer and model metrics\nmodel.compile(\n    optimizer='rmsprop',\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.2 Model Training","metadata":{}},{"cell_type":"code","source":"# saving the model training history\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=EPOCHS\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.3 Check for overfitting","metadata":{}},{"cell_type":"markdown","source":"If the deep learning CNN model gets too complex, it is likely to suffer from overfitting. \nOverfitting indicates that the model begins to memorize the training data instead of learning general patterns. \nA possible indicator of this is highly accurate model i.e. training and validation accuracies >90%. This also indicates that the model is biased to the images training data and a poor generalization on unseen images.\n\nLet us plot the accuracy and loss curves to visualize the model training process.","metadata":{}},{"cell_type":"code","source":"#Plotting train & validation loss\nplt.figure()\nplt.plot(history.history[\"loss\"],label = \"Train Loss\", color = \"black\")\nplt.plot(history.history[\"val_loss\"],label = \"Validation Loss\", color = \"blue\", linestyle=\"dashed\")\nplt.title(\"Model Losses\", color = \"darkred\", size = 15)\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting train & validation accuracy\nplt.figure()\nplt.plot(history .history[\"accuracy\"],label = \"Train Accuracy\", color = \"black\")\nplt.plot(history .history[\"val_accuracy\"],label = \"Validation Accuracy\", color = \"blue\", linestyle=\"dashed\")\nplt.title(\"Model Accuracy\", color = \"darkred\", size = 15)\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remarks:\n* Since the training accuracy and validation accuracy follow a similar trend and both increase over the epochs, the model shows no signs of overfitting.\n* Similarly, the training loss and validation loss decrease consistently, indicating a good fit between the model and the data.\n* The model can be retrained for higher epochs with a different batch size for experimentation and evaluating a possible improvement in the model accuracy.","metadata":{}},{"cell_type":"markdown","source":"# 3. Predicting unseen images from test dataset","metadata":{}},{"cell_type":"markdown","source":"# 3.1 Creating a test data pipeline","metadata":{}},{"cell_type":"code","source":"# test dataset pipeline\ntest_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n   test_subset,\n    seed=42,\n    shuffle=True,\n    image_size=(IMAGE_SIZE,IMAGE_SIZE),\n    batch_size=BATCH_SIZE\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print training labels\nts_class_names = test_dataset.class_names\nts_class_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.2 Predicting a sample image","metadata":{}},{"cell_type":"code","source":"# Fetching model predictions for sample image in test dataset\nplt.figure(figsize=(3, 3))\nfor images_batch, labels_batch in test_dataset.take(1):\n\n    first_image = images_batch[0].numpy().astype('uint8')\n    first_label = labels_batch[0].numpy()\n    print(\"first image to predict\")\n    plt.imshow(first_image)\n    print(\"actual label:\",ts_class_names[first_label])\n\n    batch_prediction = model.predict(images_batch)\n    print(\"predicted label:\",tr_class_names[np.argmax(batch_prediction[0])])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.3 Batch prediction on unseen images from test dataset","metadata":{}},{"cell_type":"code","source":"# Defining prediction function for testing images\ndef predict(model, img):\n    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n    img_array = tf.expand_dims(img_array, 0)\n\n    predictions = model.predict(img_array)\n\n    predicted_class = ts_class_names[np.argmax(predictions[0])]\n    confidence = round(100 * (np.max(predictions[0])), 2)\n    return predicted_class, confidence","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will do a few set of predictions and visualize the results to have a better idea about how our model is performing.","metadata":{}},{"cell_type":"markdown","source":"### Prediction set 1\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 15))\n\n# Iterate over the batches and then the images to display their predictions\nbatch_size = 32\nfor images, labels in test_dataset.take(12):\n    for i in range(batch_size):\n        if i >= len(images):\n            break\n\n        ax = plt.subplot(6, 6, i + 1)\n        image = tf.image.resize(images[i], (100, 100))\n        plt.imshow(image.numpy().astype(\"uint8\"))\n        predicted_class, confidence = predict(model, images[i].numpy())\n        actual_class = ts_class_names[labels[i]]\n        plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\", fontsize=8)\n        plt.axis(\"off\")\n\n    # If there are more than batch size images, break out of the loop\n    if i >= batch_size - 1:\n        break\n\n# Hide any empty subplots\nfor i in range(i + 1, batch_size):\n    plt.subplot(6,6, i + 1)\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction set 2\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 15))\n\n# Iterate over the batches and then the images to display their predictions\nbatch_size = 32\nfor images, labels in test_dataset.take(15):\n    for i in range(batch_size):\n        if i >= len(images):\n            break\n\n        ax = plt.subplot(6, 6, i + 1)\n        image = tf.image.resize(images[i], (100, 100))\n        plt.imshow(image.numpy().astype(\"uint8\"))\n        predicted_class, confidence = predict(model, images[i].numpy())\n        actual_class = ts_class_names[labels[i]]\n        plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\", fontsize=8)\n        plt.axis(\"off\")\n\n    # If there are more than batch size images, break out of the loop\n    if i >= batch_size - 1:\n        break\n\n# Hide any empty subplots\nfor i in range(i + 1, batch_size):\n    plt.subplot(6,6, i + 1)\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Concluding Notes\n\n* We created a fairly accurate fruit classifier in Keras.\n* The model accurately predicted most of the considered fruit categories. \n* The model seems to incorrectly label some of the fruit varieties with higher confidence. Since these varieties appear similar in colors and shapes, they can be challenging for the model to classify. This can be improved by -\n    * Training the model with additional data using data augmentation in Keras\n    * Experimenting with adding Batch normalization to the CNN layers to improve and stabilize the learning process\n    * Adding more layers to the neural network\n    * Adding L2 regularization\n    * Experimenting with the dropout rate, learning rate\n\nApart from the above, the model does a really good job of classifying different fruits and their variants such as raspberry,pineapple, redcurrant, grapefruit, banana, etc.","metadata":{}},{"cell_type":"markdown","source":"* Fruit image classification has numerous practical applications, from sorting ripe fruits to detecting diseases. It offers efficiency, accuracy, and potential for optimizing inventory management in various industries. Similarly, Deep Learning can also be extended to broader plant species detection, benefiting agricultural industries.Exploring these use cases can create an awareness about potential AI projects in agricultural domain.\n\n* Apart from fruit classification, Deep Learning can also be utilized for broader plant species detection. By analyzing various plant attributes, such as leaves, flowers, or fruits, the technology can identify different plant species in their natural habitat which can significantly impact the ongoing botany research, conservation efforts, and ecological studies. This demonstrates the versatility and potential applications of Deep Learning models in the agriculture and horticulture.\n\nAlso, if you're interested in getting hands-on experience on a similar exciting Deep Learning project, check out the **[Plant Species classification](https://bit.ly/43W6l3C)** on ProjectPro.","metadata":{}},{"cell_type":"markdown","source":"If you liked this notebook please remember to upvote. Thanks and Happy coding! ðŸ˜Š","metadata":{}}]}